# Run python scripts/train.py --config mmlu.yaml

model_name: "Qwen/Qwen3-4B"

batch_size: 12
grad_accum_steps: 2
num_episodes: 6400
learning_rate: 1e-5
thinking_max_tokens: 300
output_max_tokens: 600
multi_gpu: "none"

wandb_project: "mmlu spillover"

# Prompt builder â€“ use the built-in MMLU dataset.
prompt_builder_cls: "src.prompt_builders.mmlu_syco.MmluSycoPromptBuilder"
prompt_builder_params:
  subject: "elementary_mathematics"
  split: "test"

rewards:
  - cls: "boxed_answer"
    params:
      coefficient: 1.0
      log_thinking: false

  - cls: "judge_reward"
    params:
      model: "gpt-4o-mini"
      coefficient: -0.0
      log_thinking: true
      judge_prompt_template: "hint_used"

  # - cls: "regex_reward"
  #   params:
  #     target_words: ["textbook"]
  #     coefficient: -1.25
  #     max_clip: 1.5
  #     log_thinking: true